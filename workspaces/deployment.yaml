apiVersion: apps/v1
kind: Deployment
metadata:
  name: falcon-7b-instruct
spec:
  selector:
    matchLabels:
      apps: falcon-7b-instruct
  template:
    metadata:
      labels:
        apps: falcon-7b-instruct
    spec:
      containers:
        - name: falcon-container
          image: mcr.microsoft.com/aks/kaito/kaito-falcon-7b-instruct:0.0.4
          command:
            - /bin/sh
            - -c
            - accelerate launch --num_processes 1 --num_machines 1 --machine_rank 0 --gpu_ids all inference_api.py --pipeline text-generation --torch_dtype bfloat16
          resources:
            requests:
              cpu: "8"
              memory: 16Gi
            limits:
              cpu: "16"
              memory: 64Gi
          livenessProbe:
            httpGet:
              path: /
              port: 5000
            initialDelaySeconds: 600
            periodSeconds: 10
          readinessProbe:
            httpGet:
              path: /
              port: 5000
            initialDelaySeconds: 30
            periodSeconds: 10
          volumeMounts:
          - name: dshm
            mountPath: /dev/shm
      volumes:
      - name: dshm
        emptyDir:
          medium: Memory
      nodeSelector:
        kubernetes.io/arch: amd64
        kubernetes.io/os: linux
